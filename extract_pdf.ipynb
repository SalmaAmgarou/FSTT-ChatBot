{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0374938-9146-47a5-90fe-8268f3c85eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pymongo PyPDF2 pytesseract pdf2image pillow pymongo\n",
    "# sudo apt-get install tesseract-ocr (terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24de232e-7464-4bdf-be02-c8d632c9d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from PyPDF2 import PdfReader\n",
    "from pdf2image import convert_from_path\n",
    "from pymongo import MongoClient\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5031c562-2c28-4e51-b490-7fcb4bc9284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MongoDB connection\n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client['PDFs']\n",
    "original_collection = db['pdf_contents']\n",
    "cleaned_collection = db['cleaned_pdf_contents']\n",
    "# Path to the folder containing PDF files\n",
    "pdf_folder_path = 'pdf_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce73c904-0d2d-4417-b805-d19ac9bc4958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Tesseract executable (for Linux)\n",
    "pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "718534d5-6e79-4b67-8f1e-d0e0eece9ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        # Attempt to extract text using PdfReader\n",
    "        reader = PdfReader(pdf_path)\n",
    "        text = ''\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {pdf_path} using PdfReader: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_text_from_image(pdf_path):\n",
    "    try:\n",
    "        # Convert PDF pages to images\n",
    "        images = convert_from_path(pdf_path)\n",
    "        text = ''\n",
    "        for image in images:\n",
    "            text += pytesseract.image_to_string(image)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from images in {pdf_path} using Tesseract: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07dcba62-5504-47f9-ab47-81409f8d7ba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_text(content):\n",
    "    # Replace special characters\n",
    "    replacements = {\n",
    "        '\\u00e9': 'é', '\\u00e0': 'à', '\\u00e8': 'è', '\\u00f4': 'ô', '\\u00e7': 'ç',\n",
    "        '\\u00fb': 'û', '\\u00ea': 'ê', '\\u00e2': 'â', '\\u00ef': 'ï', '\\u00ee': 'î',\n",
    "        '\\u00e1': 'á', '\\u00f3': 'ó', '\\u00fa': 'ú', '\\u00f1': 'ñ', '\\u00e4': 'ä',\n",
    "        '\\u00f6': 'ö', '\\u00fc': 'ü', '\\u00e3': 'ã', '\\u00f5': 'õ'\n",
    "    }\n",
    "    for orig, repl in replacements.items():\n",
    "        content = content.replace(orig, repl)\n",
    "    \n",
    "    # Remove special characters (except French accents)\n",
    "    content = re.sub(r'[^\\w\\s\\'éàèôçûêâïîáóúñäöüãõ]', '', content)\n",
    "    \n",
    "    # Replace multiple spaces with a single space\n",
    "    content = re.sub(r'\\s+', ' ', content)\n",
    "    \n",
    "    # Remove leading and trailing spaces\n",
    "    content = content.strip()\n",
    "    \n",
    "    return content\n",
    "\n",
    "def clean_title(title):\n",
    "    # Clean the title similarly to the content\n",
    "    title = re.sub(r'[^\\w\\s\\'éàèôçûêâïîáóúñäöüãõ]', '', title)\n",
    "    title = re.sub(r'\\s+', ' ', title)\n",
    "    title = title.strip()\n",
    "    return title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b290421-6a8b-43df-8a1e-527404e459a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_files(folder_path):\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.lower().endswith('.pdf'):\n",
    "            pdf_path = os.path.join(folder_path, file_name)\n",
    "            print(f\"Processing {pdf_path}...\")\n",
    "            \n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "            if not text:  # If PdfReader failed or returned empty\n",
    "                text = extract_text_from_image(pdf_path)\n",
    "            \n",
    "            if text:\n",
    "                # Ensure proper encoding\n",
    "                text = text.encode('utf-8', 'replace').decode('utf-8')\n",
    "                file_name_encoded = file_name.encode('utf-8', 'replace').decode('utf-8')\n",
    "                \n",
    "                # Store in MongoDB\n",
    "                pdf_data = {\n",
    "                    'title': file_name_encoded,\n",
    "                    'content': text,\n",
    "                    'metadata': None\n",
    "                }\n",
    "                original_collection.insert_one(pdf_data)\n",
    "                print(f\"Stored {file_name} in MongoDB.\")\n",
    "            else:\n",
    "                print(f\"Failed to extract content from {file_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b581b158-5fc2-45b8-8b29-fea87592871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_documents():\n",
    "    documents = original_collection.find()\n",
    "    \n",
    "    for document in documents:\n",
    "        content = document['content']\n",
    "        title = document['title']\n",
    "        \n",
    "        # Clean and preprocess the content and title\n",
    "        cleaned_content = clean_text(content)\n",
    "        cleaned_title = clean_title(title)\n",
    "        \n",
    "        # Create the cleaned document\n",
    "        cleaned_document = {\n",
    "            'title': cleaned_title,\n",
    "            'content': cleaned_content,\n",
    "            'metadata': None\n",
    "        }\n",
    "        \n",
    "        # Store the cleaned document in the new collection\n",
    "        cleaned_collection.insert_one(cleaned_document)\n",
    "        \n",
    "        print(f\"Stored cleaned document with title: {cleaned_title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c266731-4b8f-4871-aca0-c96a962da94a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing pdf_data/Atelier5-1 Spark.pdf...\n",
      "Stored Atelier5-1 Spark.pdf in MongoDB.\n",
      "Processing pdf_data/Artificial_Intelligence_of_Things_AIoT_i.pdf...\n",
      "Stored Artificial_Intelligence_of_Things_AIoT_i.pdf in MongoDB.\n",
      "Processing pdf_data/Installation Cloudera QuikStrats sur VM Virtual Box.pdf...\n",
      "Stored Installation Cloudera QuikStrats sur VM Virtual Box.pdf in MongoDB.\n",
      "Processing pdf_data/Cours 1 Architecture_Big Data Fondements de BIG DATA.pdf...\n",
      "Stored Cours 1 Architecture_Big Data Fondements de BIG DATA.pdf in MongoDB.\n",
      "Processing pdf_data/KMeans(Données 2D).pdf...\n",
      "Stored KMeans(Données 2D).pdf in MongoDB.\n",
      "Processing pdf_data/Atelier YARN.pdf...\n",
      "Stored Atelier YARN.pdf in MongoDB.\n",
      "Processing pdf_data/Atelier Hive.pdf...\n",
      "Stored Atelier Hive.pdf in MongoDB.\n",
      "Processing pdf_data/Smart_Transport_and_Logistics_a_Node-RED_implement.pdf...\n",
      "Stored Smart_Transport_and_Logistics_a_Node-RED_implement.pdf in MongoDB.\n",
      "Processing pdf_data/Cours 4 Architecture_Big Data Hadoop2 YARN.pdf...\n",
      "Stored Cours 4 Architecture_Big Data Hadoop2 YARN.pdf in MongoDB.\n",
      "Processing pdf_data/Atelier3 Map Reduce sur la Plate forme Cloudera.pdf...\n",
      "Stored Atelier3 Map Reduce sur la Plate forme Cloudera.pdf in MongoDB.\n",
      "Processing pdf_data/Chapitre 1 Algorithmique et Programmation 1.pdf...\n",
      "Stored Chapitre 1 Algorithmique et Programmation 1.pdf in MongoDB.\n",
      "Processing pdf_data/Atelier6-1 Hbase (1).pdf...\n",
      "Stored Atelier6-1 Hbase (1).pdf in MongoDB.\n",
      "Processing pdf_data/ML(Note 4).pdf...\n",
      "Error extracting text from pdf_data/ML(Note 4).pdf using PdfReader: PyCryptodome is required for AES algorithm\n",
      "Stored ML(Note 4).pdf in MongoDB.\n",
      "Processing pdf_data/Cours BD Chapitre 1.pdf...\n",
      "Stored Cours BD Chapitre 1.pdf in MongoDB.\n",
      "Processing pdf_data/NB Borders (2D).pdf...\n",
      "Stored NB Borders (2D).pdf in MongoDB.\n",
      "Processing pdf_data/Atelier6-2 Hbase.pdf...\n",
      "Stored Atelier6-2 Hbase.pdf in MongoDB.\n",
      "Processing pdf_data/Chapitre_4_MQTT_ (1).pdf...\n",
      "Stored Chapitre_4_MQTT_ (1).pdf in MongoDB.\n",
      "Processing pdf_data/Chapitre_5_node red (1).pdf...\n",
      "Stored Chapitre_5_node red (1).pdf in MongoDB.\n",
      "Processing pdf_data/Naive Bayes (Iris).pdf...\n",
      "Stored Naive Bayes (Iris).pdf in MongoDB.\n",
      "Processing pdf_data/Chapitre_Filtres.pdf...\n",
      "Stored Chapitre_Filtres.pdf in MongoDB.\n",
      "Processing pdf_data/Atelier_Sqoop.pdf...\n",
      "Stored Atelier_Sqoop.pdf in MongoDB.\n",
      "Processing pdf_data/Programmation_LowCode_Salma_Amgarou.pdf...\n",
      "Stored Programmation_LowCode_Salma_Amgarou.pdf in MongoDB.\n",
      "Processing pdf_data/Bayes Naif(Play tennis).pdf...\n",
      "Error extracting text from pdf_data/Bayes Naif(Play tennis).pdf using PdfReader: PyCryptodome is required for AES algorithm\n",
      "Stored Bayes Naif(Play tennis).pdf in MongoDB.\n",
      "Processing pdf_data/ML(Note 7- Code).pdf...\n",
      "Error extracting text from pdf_data/ML(Note 7- Code).pdf using PdfReader: PyCryptodome is required for AES algorithm\n",
      "Stored ML(Note 7- Code).pdf in MongoDB.\n",
      "Processing pdf_data/ML(Note 5).pdf...\n",
      "Error extracting text from pdf_data/ML(Note 5).pdf using PdfReader: PyCryptodome is required for AES algorithm\n",
      "Stored ML(Note 5).pdf in MongoDB.\n",
      "Processing pdf_data/ML(Note 1).pdf...\n",
      "Error extracting text from pdf_data/ML(Note 1).pdf using PdfReader: PyCryptodome is required for AES algorithm\n",
      "Stored ML(Note 1).pdf in MongoDB.\n",
      "Processing pdf_data/Cours5 Architecture_Big Data Spark.pdf...\n",
      "Stored Cours5 Architecture_Big Data Spark.pdf in MongoDB.\n",
      "Processing pdf_data/Cours6 Hbase.pdf...\n",
      "Stored Cours6 Hbase.pdf in MongoDB.\n",
      "Processing pdf_data/Artificial_Intelligence_of_Things_AIoT_Technologie.pdf...\n",
      "Stored Artificial_Intelligence_of_Things_AIoT_Technologie.pdf in MongoDB.\n",
      "Processing pdf_data/TP2_IoT_capt_actio_Node_red.pdf...\n",
      "Stored TP2_IoT_capt_actio_Node_red.pdf in MongoDB.\n",
      "Processing pdf_data/ML(Note 6).pdf...\n",
      "Error extracting text from pdf_data/ML(Note 6).pdf using PdfReader: PyCryptodome is required for AES algorithm\n",
      "Stored ML(Note 6).pdf in MongoDB.\n",
      "Processing pdf_data/Bayes Naïf (Classification des emails).pdf...\n",
      "Stored Bayes Naïf (Classification des emails).pdf in MongoDB.\n",
      "Processing pdf_data/MachineLearningInAction.pdf...\n",
      "Stored MachineLearningInAction.pdf in MongoDB.\n",
      "Processing pdf_data/Atelier HDFS.pdf...\n",
      "Stored Atelier HDFS.pdf in MongoDB.\n",
      "Processing pdf_data/Consignes_Rapport_PFE.pdf...\n",
      "Stored Consignes_Rapport_PFE.pdf in MongoDB.\n",
      "Processing pdf_data/Programmation avancée avec python.pdf...\n",
      "Stored Programmation avancée avec python.pdf in MongoDB.\n",
      "Processing pdf_data/Chapitre2  Les éléments de base d’un Algorithme et leur représentation en Langage C.pdf...\n",
      "Stored Chapitre2  Les éléments de base d’un Algorithme et leur représentation en Langage C.pdf in MongoDB.\n",
      "Processing pdf_data/Bayes Naif(message abusif).pdf...\n",
      "Stored Bayes Naif(message abusif).pdf in MongoDB.\n",
      "Processing pdf_data/Atelier5-2 Spark.pdf...\n",
      "Stored Atelier5-2 Spark.pdf in MongoDB.\n",
      "Processing pdf_data/Installation et paramétrage  DEv-C++.pdf...\n",
      "Stored Installation et paramétrage  DEv-C++.pdf in MongoDB.\n",
      "Processing pdf_data/KNN (Groupement des caractères).pdf...\n",
      "Stored KNN (Groupement des caractères).pdf in MongoDB.\n",
      "Processing pdf_data/2D data( Naive Bayes Borders ).pdf...\n",
      "Stored 2D data( Naive Bayes Borders ).pdf in MongoDB.\n",
      "Processing pdf_data/TP2_actio_Arduino_Raspberry.pdf...\n",
      "Stored TP2_actio_Arduino_Raspberry.pdf in MongoDB.\n",
      "Processing pdf_data/Chapitre  3  La sélection en Algorithmique et en Langage C.pdf...\n",
      "Stored Chapitre  3  La sélection en Algorithmique et en Langage C.pdf in MongoDB.\n",
      "Processing pdf_data/KMeans (Groupement des caractères).pdf...\n",
      "Error extracting text from pdf_data/KMeans (Groupement des caractères).pdf using PdfReader: PyCryptodome is required for AES algorithm\n",
      "Stored KMeans (Groupement des caractères).pdf in MongoDB.\n",
      "Processing pdf_data/Atelier5-4 PySpark (Customer Churn using LR).pdf...\n",
      "Stored Atelier5-4 PySpark (Customer Churn using LR).pdf in MongoDB.\n",
      "Processing pdf_data/Atelier5-3 Spark.pdf...\n",
      "Stored Atelier5-3 Spark.pdf in MongoDB.\n",
      "Processing pdf_data/Chapitre 4 Les boucles en Algorithmique et en Langage C.pdf...\n",
      "Stored Chapitre 4 Les boucles en Algorithmique et en Langage C.pdf in MongoDB.\n",
      "Processing pdf_data/ML(Note 7).pdf...\n",
      "Error extracting text from pdf_data/ML(Note 7).pdf using PdfReader: PyCryptodome is required for AES algorithm\n",
      "Stored ML(Note 7).pdf in MongoDB.\n",
      "Processing pdf_data/Cours 3 Architecture_Big Data Map Reduce.pdf...\n",
      "Stored Cours 3 Architecture_Big Data Map Reduce.pdf in MongoDB.\n",
      "Stored cleaned document with title: Atelier51 Sparkpdf\n",
      "Stored cleaned document with title: Artificial_Intelligence_of_Things_AIoT_ipdf\n",
      "Stored cleaned document with title: Installation Cloudera QuikStrats sur VM Virtual Boxpdf\n",
      "Stored cleaned document with title: Cours 1 Architecture_Big Data Fondements de BIG DATApdf\n",
      "Stored cleaned document with title: KMeansDonnées 2Dpdf\n",
      "Stored cleaned document with title: Atelier YARNpdf\n",
      "Stored cleaned document with title: Atelier Hivepdf\n",
      "Stored cleaned document with title: Smart_Transport_and_Logistics_a_NodeRED_implementpdf\n",
      "Stored cleaned document with title: Cours 4 Architecture_Big Data Hadoop2 YARNpdf\n",
      "Stored cleaned document with title: Atelier3 Map Reduce sur la Plate forme Clouderapdf\n",
      "Stored cleaned document with title: Chapitre 1 Algorithmique et Programmation 1pdf\n",
      "Stored cleaned document with title: Atelier61 Hbase 1pdf\n",
      "Stored cleaned document with title: MLNote 4pdf\n",
      "Stored cleaned document with title: Cours BD Chapitre 1pdf\n",
      "Stored cleaned document with title: NB Borders 2Dpdf\n",
      "Stored cleaned document with title: Atelier62 Hbasepdf\n",
      "Stored cleaned document with title: Chapitre_4_MQTT_ 1pdf\n",
      "Stored cleaned document with title: Chapitre_5_node red 1pdf\n",
      "Stored cleaned document with title: Naive Bayes Irispdf\n",
      "Stored cleaned document with title: Chapitre_Filtrespdf\n",
      "Stored cleaned document with title: Atelier_Sqooppdf\n",
      "Stored cleaned document with title: Programmation_LowCode_Salma_Amgaroupdf\n",
      "Stored cleaned document with title: Bayes NaifPlay tennispdf\n",
      "Stored cleaned document with title: MLNote 7 Codepdf\n",
      "Stored cleaned document with title: MLNote 5pdf\n",
      "Stored cleaned document with title: MLNote 1pdf\n",
      "Stored cleaned document with title: Cours5 Architecture_Big Data Sparkpdf\n",
      "Stored cleaned document with title: Cours6 Hbasepdf\n",
      "Stored cleaned document with title: Artificial_Intelligence_of_Things_AIoT_Technologiepdf\n",
      "Stored cleaned document with title: TP2_IoT_capt_actio_Node_redpdf\n",
      "Stored cleaned document with title: MLNote 6pdf\n",
      "Stored cleaned document with title: Bayes Naïf Classification des emailspdf\n",
      "Stored cleaned document with title: MachineLearningInActionpdf\n",
      "Stored cleaned document with title: Atelier HDFSpdf\n",
      "Stored cleaned document with title: Consignes_Rapport_PFEpdf\n",
      "Stored cleaned document with title: Programmation avancee avec pythonpdf\n",
      "Stored cleaned document with title: Chapitre2 Les éléments de base dun Algorithme et leur représentation en Langage Cpdf\n",
      "Stored cleaned document with title: Bayes Naifmessage abusifpdf\n",
      "Stored cleaned document with title: Atelier52 Sparkpdf\n",
      "Stored cleaned document with title: Installation et paramétrage DEvCpdf\n",
      "Stored cleaned document with title: KNN Groupement des caractèrespdf\n",
      "Stored cleaned document with title: 2D data Naive Bayes Borders pdf\n",
      "Stored cleaned document with title: TP2_actio_Arduino_Raspberrypdf\n",
      "Stored cleaned document with title: Chapitre 3 La sélection en Algorithmique et en Langage Cpdf\n",
      "Stored cleaned document with title: KMeans Groupement des caractèrespdf\n",
      "Stored cleaned document with title: Atelier54 PySpark Customer Churn using LRpdf\n",
      "Stored cleaned document with title: Atelier53 Sparkpdf\n",
      "Stored cleaned document with title: Chapitre 4 Les boucles en Algorithmique et en Langage Cpdf\n",
      "Stored cleaned document with title: MLNote 7pdf\n",
      "Stored cleaned document with title: Cours 3 Architecture_Big Data Map Reducepdf\n"
     ]
    }
   ],
   "source": [
    "# Run the scripts\n",
    "process_pdf_files(pdf_folder_path)\n",
    "process_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1eced2d-18b4-4d57-acd1-f439a50db819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored documents in pdf_data/pdf_contents.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def fetch_documents_and_store_in_json(collection, output_file):\n",
    "    documents = collection.find({}, {'_id': 0, 'title': 1, 'content': 1, 'metadata': 1})\n",
    "    \n",
    "    document_list = list(documents)\n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(document_list, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Stored documents in {output_file}\")\n",
    "\n",
    "# Define the output JSON file path\n",
    "output_file_path = 'pdf_data/pdf_contents.json'\n",
    "\n",
    "# Fetch documents and store in JSON file\n",
    "fetch_documents_and_store_in_json(original_collection, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d6bba8-33d1-44fe-a632-5ecca959b8de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
